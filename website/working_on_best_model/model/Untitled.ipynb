{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised CNN\n",
      "768\n",
      "1024\n",
      "768\n",
      "1024\n",
      "Initialised Encoder\n",
      "592\n",
      "2048\n",
      "512\n",
      "512\n",
      "1024\n",
      "512\n",
      "512\n",
      "502\n",
      "Initialised Decoder\n",
      "WARNING:tensorflow:From <ipython-input-1-af75194a8303>:115 in __init__.: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "(502, 80),embedding_1:0\n",
      "(3, 3, 1, 64),conv1/w:0\n",
      "(3, 3, 64, 128),conv2/w:0\n",
      "(3, 3, 128, 256),conv3/w:0\n",
      "(256,),BatchNorm/beta:0\n",
      "(256,),BatchNorm/moving_mean:0\n",
      "(256,),BatchNorm/moving_variance:0\n",
      "(3, 3, 256, 256),conv4/w:0\n",
      "(3, 3, 256, 512),conv5/w:0\n",
      "(512,),BatchNorm_1/beta:0\n",
      "(512,),BatchNorm_1/moving_mean:0\n",
      "(512,),BatchNorm_1/moving_variance:0\n",
      "(3, 3, 512, 512),conv6/w:0\n",
      "(512,),BatchNorm_2/beta:0\n",
      "(512,),BatchNorm_2/moving_mean:0\n",
      "(512,),BatchNorm_2/moving_variance:0\n",
      "(1, 20, 512),Attention_Enchidden_fw_1:0\n",
      "(1, 20, 512),Attention_Enchidden_bw_1:0\n",
      "(768, 1024),BiRNN/FW/Attention_Enc.BiLSTMEncoder_fw.Gates.W:0\n",
      "(1024,),BiRNN/FW/Attention_Enc.BiLSTMEncoder_fw.Gates.b:0\n",
      "(768, 1024),BiRNN/BW/Attention_Enc.BiLSTMEncoder_bw.Gates.W:0\n",
      "(1024,),BiRNN/BW/Attention_Enc.BiLSTMEncoder_bw.Gates.b:0\n",
      "(1, 1536),Attention_Dechidden_dec_1:0\n",
      "(592, 2048),RNN/Attention_Dec.AttentionCell.Gates.W:0\n",
      "(2048,),RNN/Attention_Dec.AttentionCell.Gates.b:0\n",
      "(512, 512),RNN/Attention_Dec.AttentionCell.target_t.W:0\n",
      "(1024, 512),RNN/Attention_Dec.AttentionCell.output_t.W:0\n",
      "(512, 502),logits.W:0\n",
      "(502,),logits.b:0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Image' has no attribute 'open'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-af75194a8303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    155\u001b[0m \t)\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_hand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-af75194a8303>\u001b[0m in \u001b[0;36mpredict_hand\u001b[0;34m(self, set, batch_size, visualize)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mimgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m                         \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1a0fcb9fb1.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Image' has no attribute 'open'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import cnn\n",
    "from ops import Embedding,Attention_Enc,Attention_Dec\n",
    "from data_gen import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import display, Math, Latex, Image\n",
    "\n",
    "import numpy as np\n",
    "imgs = np.load('pred_imgs_hw.npy')\n",
    "preds = np.load('pred_latex_hw.npy')\n",
    "properties = np.load('properties.npy').tolist()\n",
    "displayPreds = lambda Y: display(Math(Y.split('#END')[0]))\n",
    "idx_to_chars = lambda Y: ' '.join(map(lambda x: properties['idx_to_char'][x],Y))\n",
    "#displayIdxs = lambda Y: display(Math(''.join(map(lambda x: properties['idx_to_char'][x],Y))))\n",
    "\n",
    "import PIL.Image\n",
    "from cStringIO import StringIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "\tdef __init__(self,phase,vocab_list_path=None,data_base_dir=None,data_path=None,formula_map=None,test_data_map=None,train_data_map=None,validate_data_map=None,cnn_pretrain_path=None,batch_size=20):\n",
    "\n",
    "\t\tself.map_v={}\n",
    "\t\tself.map_i={}\n",
    "\n",
    "\t\tself.map_v['GO'] = 1\n",
    "\t\tself.map_v['EOS'] = 2\n",
    "\t\tself.map_v['PAD'] = 0\n",
    "\t\tself.map_v['UNKNOWN'] = 3\n",
    "\n",
    "\t\tself.map_i[0] = 'PAD'\n",
    "\t\tself.map_i[1] = 'GO'\n",
    "\t\tself.map_i[2] = 'EOS'\n",
    "\t\tself.map_i[3] = 'UNKNOWN'\n",
    "\n",
    "\t\tself.embedding_dim = 80\n",
    "\t\tself.target_vocab_size = 502\n",
    "\t\tself.ENC_MAX_WIDTH = 50\n",
    "\t\tself.ENC_MAX_HEIGHT = 20\n",
    "\t\tself.ENC_OP_DIM = 512\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.ENC_DIM = 256\n",
    "\t\tself.DEC_DIM = 512\n",
    "\t\tself.MAX_CT_VEC_LENGTH = self.ENC_MAX_HEIGHT*self.ENC_MAX_WIDTH\n",
    "\n",
    "\t\tself.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "\n",
    "\n",
    "\t\tself.img_ip = tf.placeholder(shape=(None,None,None,1),dtype=tf.float32,name='data')\n",
    "\t\tself.conv_op = tf.placeholder(shape=(None,None,None,512),dtype=tf.float32,name='convop')\n",
    "\t\tself.decoder_input = tf.placeholder(shape=(None,None),dtype=tf.int32,name='seq')\n",
    "\n",
    "\t\tself.embedding_seqs = Embedding('embedding',self.target_vocab_size,self.embedding_dim,self.decoder_input)\n",
    "\n",
    "\t\tself.conv_op = cnn.CNN_Net(self.img_ip)\n",
    "\t\tprint \"Initialised CNN\"\n",
    "\t\tself.encoder_output = Attention_Enc('Attention_Enc',self.conv_op,self.ENC_DIM,self.ENC_MAX_WIDTH,self.ENC_MAX_HEIGHT,self.ENC_OP_DIM,self.batch_size)\n",
    "\t\tprint \"Initialised Encoder\"\n",
    "\t\tself.decoder_output ,self.logits= Attention_Dec('Attention_Dec',self.encoder_output,self.embedding_seqs,self.DEC_DIM,self.MAX_CT_VEC_LENGTH,self.ENC_OP_DIM,self.batch_size,self.embedding_dim,self.target_vocab_size)\n",
    "\t\tprint \"Initialised Decoder\"\n",
    "\n",
    "\t\tself.w_fp = h5py.File(cnn_pretrain_path)\n",
    "\t\tcnn_weight_dict={}\n",
    "\t\tcnn_weight_dict['conv1/w:0'] = self.w_fp['conv1/conv1.W:0'][...]\n",
    "\t\tcnn_weight_dict['conv2/w:0'] = self.w_fp['conv2/conv2.W:0'][...]\n",
    "\t\tcnn_weight_dict['conv3/w:0'] = self.w_fp['conv3/conv3.W:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm/beta:0'] = self.w_fp['conv3//beta:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm/moving_mean:0'] = self.w_fp['conv3//moving_mean:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm/moving_variance:0'] = self.w_fp['conv3//moving_variance:0'][...]\n",
    "\n",
    "\t\tcnn_weight_dict['conv4/w:0'] = self.w_fp['conv4/conv4.W:0'][...]\n",
    "\t\tcnn_weight_dict['conv5/w:0'] = self.w_fp['conv5/conv5.W:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm_1/beta:0'] = self.w_fp['conv5//beta:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm_1/moving_mean:0'] = self.w_fp['conv5//moving_mean:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm_1/moving_variance:0'] = self.w_fp['conv5//moving_variance:0'][...]\n",
    "\n",
    "\t\tcnn_weight_dict['conv6/w:0'] = self.w_fp['conv6/conv6.W:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm_2/beta:0'] = self.w_fp['conv6//beta:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm_2/moving_mean:0'] = self.w_fp['conv6//moving_mean:0'][...]\n",
    "\t\tcnn_weight_dict['BatchNorm_2/moving_variance:0'] = self.w_fp['conv6//moving_variance:0'][...]\n",
    "\n",
    "\t\tcnn_weight_dict['embedding_1:0']=self.w_fp['Embedding/Embedding:0'][...]\n",
    "\t\tcnn_weight_dict['Attention_Enchidden_fw_1:0'] = self.w_fp['AttLSTM.Enc_.init.h0_1:0'][...]\n",
    "\t\tcnn_weight_dict['Attention_Enchidden_bw_1:0'] = self.w_fp['AttLSTM.Enc_init.h0_2:0'][...]\n",
    "\t\tcnn_weight_dict['BiRNN/FW/Attention_Enc.BiLSTMEncoder_fw.Gates.W:0'] = self.w_fp['scan/while/BiRNN/FW/FW/while/AttLSTM.BiLSTMEncoder_fw.Gates/AttLSTM.BiLSTMEncoder_fw.Gates.W:0'][...]\n",
    "\t\tcnn_weight_dict['BiRNN/FW/Attention_Enc.BiLSTMEncoder_fw.Gates.b:0'] = self.w_fp['scan/while/BiRNN/FW/FW/while/AttLSTM.BiLSTMEncoder_fw.Gates/AttLSTM.BiLSTMEncoder_fw.Gates.b:0'][...]\n",
    "\n",
    "\t\tcnn_weight_dict['BiRNN/BW/Attention_Enc.BiLSTMEncoder_bw.Gates.W:0'] = self.w_fp['scan/while/BiRNN/BW/BW/while/AttLSTM.BiLSTMEncoder_bw.Gates/AttLSTM.BiLSTMEncoder_bw.Gates.W:0'][...]\n",
    "\t\tcnn_weight_dict['BiRNN/BW/Attention_Enc.BiLSTMEncoder_bw.Gates.b:0'] = self.w_fp['scan/while/BiRNN/BW/BW/while/AttLSTM.BiLSTMEncoder_bw.Gates/AttLSTM.BiLSTMEncoder_bw.Gates.b:0'][...]\n",
    "\t\tcnn_weight_dict['Attention_Dechidden_dec_1:0'] = self.w_fp['AttLSTM.Decoder.init.h0:0'][...]\n",
    "\t\tcnn_weight_dict['RNN/Attention_Dec.AttentionCell.Gates.W:0'] = self.w_fp['RNN/while/AttLSTM.AttentionCell.Gates/AttLSTM.AttentionCell.Gates.W:0'][...]\n",
    "\t\tcnn_weight_dict['RNN/Attention_Dec.AttentionCell.Gates.b:0'] = self.w_fp['RNN/while/AttLSTM.AttentionCell.Gates/AttLSTM.AttentionCell.Gates.b:0'][...]\n",
    "\n",
    "\t\tcnn_weight_dict['RNN/Attention_Dec.AttentionCell.target_t.W:0'] = self.w_fp['RNN/while/AttLSTM.AttentionCell.target_t/AttLSTM.AttentionCell.target_t.W:0'][...]\n",
    "\t\tcnn_weight_dict['RNN/Attention_Dec.AttentionCell.output_t.W:0'] = self.w_fp['RNN/while/AttLSTM.AttentionCell.output_t/AttLSTM.AttentionCell.output_t.W:0'][...]\n",
    "\t\tcnn_weight_dict['logits.W:0'] = self.w_fp['MLP.1/MLP.1.W:0'][...]\n",
    "\t\tcnn_weight_dict['logits.b:0'] = self.w_fp['MLP.1/MLP.1.b:0'][...]\n",
    "\n",
    "\n",
    "\t\tfor param in tf.all_variables():\n",
    "\t\t\tprint \"{},{}\".format(param.get_shape(),param.name)\n",
    "\t\t\tif 'conv' in param.name or 'Batch' in param.name :\n",
    "\t\t\t\tself.sess.run(param.assign(cnn_weight_dict[param.name]))\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.sess.run(param.assign(cnn_weight_dict[param.name]))\n",
    "\n",
    "\tdef predict_hand(self,set='test',batch_size=1,visualize=True):\n",
    "\t\timgs=[]\n",
    "\t\tfor i in range(batch_size):\n",
    "\t\t\timgs.append(np.asarray(Image.open('1a0fcb9fb1.png').convert('YCbCr'))[:,:,0][:,:,None])\n",
    "\n",
    "\t\timgs = np.asarray(imgs,dtype=np.float32)\n",
    "\n",
    "\t\tinp_seqs = np.zeros((batch_size,160)).astype('int32')\n",
    "\t\tprint imgs.shape\n",
    "\n",
    "\t\tinp_seqs[:,0] = np.load('properties.npy').tolist()['char_to_idx']['#START']\n",
    "\n",
    "\t\tfor i in xrange(1,160):\n",
    "\t\t\tinput_feed={}\n",
    "\t\t\tinput_feed[self.img_ip.name] = imgs\n",
    "\t\t\tinput_feed[self.decoder_input.name] = inp_seqs[:,:i]\n",
    "\t\t\toutput_feed = [ self.logits,self.conv_op]\n",
    "\t\t\top = self.sess.run(output_feed,input_feed)\n",
    "\t\t\tprediction = tf.to_int32(tf.argmax( op[0], 2))\n",
    "\t\t\tprediction_num = np.array(prediction.eval(session=self.sess))\n",
    "\t\t\tinp_seqs[:,i] = prediction_num[:,i-1]\n",
    "\t\tnp.save('pred_imgs_hw',imgs)\n",
    "\t\tnp.save('pred_latex_hw',inp_seqs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obj = Model(\n",
    "\t'test',\n",
    "\tcnn_pretrain_path='rweights.h5',\n",
    "\tbatch_size=1\n",
    "\t)\n",
    "\n",
    "obj.predict_hand()\n",
    "\n",
    "\n",
    "# batch_size=1\n",
    "# from PIL import Image as Img\n",
    "# for i in xrange(batch_size):\n",
    "#     preds_chars = idx_to_chars(preds[i,1:]).replace('$','')\n",
    "#     print \"Original (Input) Image: %d\"%(i+1)\n",
    "#     showarray(imgs[i][0])\n",
    "#     print \"Predicted Latex\"\n",
    "#     print preds_chars.split('#END')[0]\n",
    "#     print \"\\nRendering the predicted latex\"\n",
    "#     displayPreds(preds_chars)\n",
    "#     print \"\\n\"\n",
    "\n",
    "# print repr(preds_chars).split('#END')[0]\n",
    "# #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
